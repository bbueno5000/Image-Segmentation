{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOFYX5yFG7wIqqojz7U9+ay"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install git+https://github.com/tensorflow/examples.git"],"metadata":{"id":"VeUUtJKiinH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-5rPfq3ieYN"},"outputs":[],"source":["\"\"\"\n","TODO: docstring\n","\"\"\"\n","import matplotlib.pyplot as pyplot\n","import tensorflow\n","import tensorflow_datasets\n","import tensorflow_examples.models.pix2pix.pix2pix as pix2pix\n","\n","def create_mask(pred_mask):\n","    \"\"\"\n","    TODO: docstring\n","    \"\"\"\n","    pred_mask = tensorflow.argmax(pred_mask, axis=-1)\n","    pred_mask = pred_mask[..., tensorflow.newaxis]\n","    return pred_mask[0]\n","\n","def display(display_list):\n","    \"\"\"\n","    TODO: docstring\n","    \"\"\"\n","    pyplot.figure(figsize=(15, 15))\n","    title = ['Input Image', 'True Mask', 'Predicted Mask']\n","    for i in range(len(display_list)):\n","        pyplot.subplot(1, len(display_list), i+1)\n","        pyplot.title(title[i])\n","        pyplot.imshow(tensorflow.keras.utils.array_to_img(display_list[i]))\n","        pyplot.axis('off')\n","    pyplot.show()\n","\n","def load_image(datapoint):\n","    \"\"\"\n","    TODO: docstring\n","    \"\"\"\n","    input_image = tensorflow.image.resize(datapoint['image'], (128, 128))\n","    input_mask = tensorflow.image.resize(\n","        datapoint['segmentation_mask'], (128, 128))\n","    input_image, input_mask = normalize(input_image, input_mask)\n","    return input_image, input_mask\n","\n","def normalize(input_image, input_mask):\n","    \"\"\"\n","    TODO: docstring\n","    \"\"\"\n","    input_image = tensorflow.cast(input_image, tensorflow.float32) / 255.0\n","    input_mask -= 1\n","    return input_image, input_mask\n","\n","def show_predictions(dataset=None, num=1):\n","    \"\"\"\n","    TODO: docstring\n","    \"\"\"\n","    if dataset:\n","        for image, mask in dataset.take(num):\n","          pred_mask = model.predict(image)\n","          display([image[0], mask[0], create_mask(pred_mask)])\n","    else:\n","        display([\n","            sample_image, sample_mask,\n","            create_mask(model.predict(sample_image[tensorflow.newaxis, ...]))])\n","\n","def unet_model(output_channels:int):\n","    \"\"\"\n","    TODO: docstring\n","    \"\"\"\n","    inputs = tensorflow.keras.layers.Input(shape=[128, 128, 3])\n","    # downsampling through the model\n","    skips = down_stack(inputs)\n","    x = skips[-1]\n","    skips = reversed(skips[:-1])\n","    # upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        concat = tensorflow.keras.layers.Concatenate()\n","        x = concat([x, skip])\n","    # this is the last layer of the model\n","    last = tensorflow.keras.layers.Conv2DTranspose(\n","        filters=output_channels, kernel_size=3,\n","        strides=2, padding='same') #64x64 -> 128x128\n","    x = last(x)\n","    return tensorflow.keras.Model(inputs=inputs, outputs=x)\n","\n","class Augment(tensorflow.keras.layers.Layer):\n","    \"\"\"\n","    TODO: docstring\n","    \"\"\"\n","    def __init__(self, seed=42):\n","        \"\"\"\n","        TODO: docstring\n","        \"\"\"\n","        super().__init__()\n","        # both use the same seed, so they'll make the same random changes\n","        self.augment_inputs = tensorflow.keras.layers.RandomFlip(\n","            mode='horizontal', seed=seed)\n","        self.augment_labels = tensorflow.keras.layers.RandomFlip(\n","            mode='horizontal', seed=seed)\n","\n","    def call(self, inputs, labels):\n","        \"\"\"\n","        TODO: docstring\n","        \"\"\"\n","        inputs = self.augment_inputs(inputs)\n","        labels = self.augment_labels(labels)\n","        return inputs, labels\n","\n","class DisplayCallback(tensorflow.keras.callbacks.Callback):\n","    \"\"\"\n","    TODO: docstring\n","    \"\"\"\n","    def on_epoch_end(self, epoch, logs=None):\n","        \"\"\"\n","        TODO: docstring\n","        \"\"\"\n","        show_predictions()\n","        print ('\\nsample Prediction after epoch {}\\n'.format(epoch+1))\n","\n","dataset, info = tensorflow_datasets.load('oxford_iiit_pet:3.*.*', with_info=True)\n","\n","TRAIN_LENGTH = info.splits['train'].num_examples\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 1000\n","STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n","\n","train_images = dataset['train'].map(\n","    load_image, num_parallel_calls=tensorflow.data.AUTOTUNE)\n","\n","test_images = dataset['test'].map(\n","    load_image, num_parallel_calls=tensorflow.data.AUTOTUNE)\n","\n","train_batches = (\n","    train_images\n","    .cache()\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE)\n","    .repeat()\n","    .map(Augment())\n","    .prefetch(buffer_size=tensorflow.data.AUTOTUNE))\n","\n","test_batches = test_images.batch(BATCH_SIZE)\n","\n","for images, masks in train_batches.take(2):\n","    sample_image, sample_mask = images[0], masks[0]\n","    display([sample_image, sample_mask])\n","\n","base_model = tensorflow.keras.applications.MobileNetV2(\n","    input_shape=[128, 128, 3], include_top=False)\n","\n","# use the activations of these layers\n","layer_names = [\n","    'block_1_expand_relu',   # 64x64\n","    'block_3_expand_relu',   # 32x32\n","    'block_6_expand_relu',   # 16x16\n","    'block_13_expand_relu',  # 8x8\n","    'block_16_project']      # 4x4\n","\n","base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n","\n","# create the feature extraction model\n","down_stack = tensorflow.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n","\n","down_stack.trainable = False\n","\n","up_stack = [\n","    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n","    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n","    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n","    pix2pix.upsample(64, 3)]   # 32x32 -> 64x64\n","\n","model = unet_model(output_channels=3)\n","\n","model.compile(\n","    optimizer='adam', metrics=['accuracy'],\n","    loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n","# NOTE: The loss function for training vector inputs should be\n","# SparseCategoricalCrossentropy, which is incorrectly stated in the tutorial.\n","\n","tensorflow.keras.utils.plot_model(model, show_shapes=True)\n","\n","show_predictions()\n","\n","VAL_SUBSPLITS = 5\n","VALIDATION_STEPS = info.splits['test'].num_examples // BATCH_SIZE // VAL_SUBSPLITS\n","\n","model_history = model.fit(\n","    train_batches, epochs=100,\n","    steps_per_epoch=STEPS_PER_EPOCH, validation_steps=VALIDATION_STEPS,\n","    validation_data=test_batches, callbacks=[DisplayCallback()])\n","\n","loss = model_history.history['loss']\n","val_loss = model_history.history['val_loss']\n","\n","pyplot.figure()\n","pyplot.plot(model_history.epoch, loss, 'r', label='Training loss')\n","pyplot.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\n","pyplot.title('Training and Validation Loss')\n","pyplot.xlabel('Epoch')\n","pyplot.ylabel('Loss Value')\n","pyplot.ylim([0, 1])\n","pyplot.legend()\n","pyplot.show()\n","\n","show_predictions(test_batches, 3)"]}]}